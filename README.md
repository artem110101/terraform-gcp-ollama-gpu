# terraform-gcp-ollama-gpu ğŸš€ğŸ¦™

Spin up a **low-cost** pre-emptible (spot) GPU VM on Google Cloud that auto-installs CUDA and is ready for **Ollama** or any other LLM workload.

## Why? ğŸ¤”
* ğŸ’¸  Spot pricing keeps costs tiny.  
* ğŸ”  No secrets in the repo â€“ all values are fed in via variables.  
* ğŸ› ï¸  One `terraform apply` sets up VPC, firewall, static IP, service account **and** the VM (with CUDA installed on first boot).  

## Quick start âš¡
